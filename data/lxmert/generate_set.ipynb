{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get text data from LXMERT pretraining data\n",
    "For bert-base-uncased text-only pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move to root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS_WITH_LABELS = {\"vqa\", \"gqa\", \"visual7w\"}\n",
    "TASK_NAMES = {\"vqa\", \"gqa\", \"visual7w\", \"mscoco\", \"vg\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mlm_text_from_lxmert_datafile(datafile, to_file):\n",
    "    with open(datafile, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open(to_file, \"a\") as f:\n",
    "        for example in data:\n",
    "            task_names = example[\"sentf\"].keys()\n",
    "            for task_name in task_names:\n",
    "                assert task_name in TASK_NAMES\n",
    "                # questions should have their answers appended\n",
    "                if task_name in TASKS_WITH_LABELS:\n",
    "                    for ex_ix, ex_part in enumerate(example[\"sentf\"][task_name]):\n",
    "                        ans_alternatives = example[\"labelf\"][task_name][ex_ix]\n",
    "                        # for some reason, some questions don't have answers in the data. skip them\n",
    "                        if len(ans_alternatives) == 0:\n",
    "                            continue\n",
    "                        best_ans = list(ans_alternatives.keys())[np.argmax(list(ans_alternatives.values()))]\n",
    "                        text = ex_part + \" \" + best_ans.capitalize()\n",
    "                        text = text.strip()\n",
    "                        if text[-1] not in {'!', '.'}:\n",
    "                            text = text + \".\"\n",
    "                        json_entry = {\"text\": text}\n",
    "                        json.dump(json_entry, f)\n",
    "                        f.write(\"\\n\")\n",
    "                # captions are just added as they are\n",
    "                else:\n",
    "                    for _, ex_part in enumerate(example[\"sentf\"][task_name]):\n",
    "                        json_entry = {\"text\": ex_part.strip()}\n",
    "                        json.dump(json_entry, f)\n",
    "                        f.write(\"\\n\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FILE = \"data/lxmert/train_mlm.jsonl\"\n",
    "open(OUT_FILE, 'w').close() #clear the file\n",
    "save_mlm_text_from_lxmert_datafile(\"data/lxmert/mscoco_nominival.json\", OUT_FILE)\n",
    "save_mlm_text_from_lxmert_datafile(\"data/lxmert/mscoco_train.json\", OUT_FILE)\n",
    "save_mlm_text_from_lxmert_datafile(\"data/lxmert/vgnococo.json\", OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FILE = \"data/lxmert/val_mlm.jsonl\"\n",
    "open(OUT_FILE, 'w').close() #clear the file\n",
    "save_mlm_text_from_lxmert_datafile(\"data/lxmert/mscoco_minival.json\", OUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dl4nlp_assignment_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05753275db4c417a6068616f81db8df1fa4ccdafd9acd0a9b6ad9f4706cb5748"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
