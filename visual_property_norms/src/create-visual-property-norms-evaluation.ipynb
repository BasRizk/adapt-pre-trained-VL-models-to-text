{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Visual Property Norms Evaluation \n",
    "\n",
    "This notebook creates the MLM queries used for the Visual Property Norms evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(\"data/norms.dat\")\n",
    "data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_data = data[data[\"feature type\"]==\"visual perceptual\"].drop(columns=[\"feature type\"])\n",
    "\n",
    "print(f\"Number of concepts with visual perceptual feature types: {len(visual_data.concept.unique())}\")\n",
    "print(f\"Number of unique visual features: {len(visual_data.feature.unique())}\")\n",
    "print(f\"Number of lines in visual perceptual data: {len(visual_data)}\")\n",
    "print(\"Examples:\")\n",
    "print(visual_data.concept.unique()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose most common feature if there are alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_FEATURE_REPLACEMENTS = {\"has a skin\": \"has skin\", \n",
    "                              \"is furry\": \"has fur\", \n",
    "                              \"is stream-lined\": \"is streamlined\",\n",
    "                              \"is made of material\": \"made of fabric\",\n",
    "                              \"made of material\": \"made of fabric\",\n",
    "                              \"is hairy\": \"has fur\",\n",
    "                              \"made of porcelain\": \"made of ceramic\",\n",
    "                              \"is see through\": \"is transparent\",\n",
    "                              \"is ceramic\": \"made of ceramic\",\n",
    "                              \"made of clay\": \"made of ceramic\",\n",
    "                              \"is translucent\": \"is transparent\",\n",
    "                              \"has a cable\": \"has a wire\",\n",
    "                              \"has wires\": \"has a wire\",\n",
    "                              \"made of wires\": \"has a wire\",\n",
    "                              \"has a hard skin\": \"has hard skin\",\n",
    "                              \"has a tough skin\": \"has tough skin\",\n",
    "                              \"is see-through\": \"is transparent\",\n",
    "                              \"is rounded\": \"is round\",\n",
    "                              \"has round\": \"is round\",\n",
    "                              \"has a pip\": \"has pips\"}\n",
    "\n",
    "def get_participant_counts_from_participant_list(participant_list):\n",
    "    #input example: \"p 3 29 / 14\"\n",
    "    participant_list = participant_list.split()[1:]\n",
    "\n",
    "    prev_split_ix = 0\n",
    "    counts = []\n",
    "    for ix, val in enumerate(participant_list):\n",
    "        if val==\"/\":\n",
    "            counts.append(ix-prev_split_ix)\n",
    "            prev_split_ix = ix+1\n",
    "    counts.append(len(participant_list)-prev_split_ix)\n",
    "    return counts\n",
    "\n",
    "def pick_most_common_feature(row):\n",
    "    if \"_\" not in row[\"feature\"]:\n",
    "        return row[\"feature\"] #just pick the listed one if there are no alternatives\n",
    "    else:\n",
    "        pick_ix = np.argmax(row[\"participant list\"])\n",
    "        most_common_feature = row[\"feature alternatives\"].split(\"; \")[pick_ix]\n",
    "        most_common_feature = KNOWN_FEATURE_REPLACEMENTS[most_common_feature] if most_common_feature in KNOWN_FEATURE_REPLACEMENTS else most_common_feature\n",
    "\n",
    "        feature_variations = [row[\"feature\"].split(\"_\")[0]]\n",
    "        feature_variations.append(row[\"feature\"].split(\"_\")[1])\n",
    "        feature_variations.append((\" \").join([row[\"feature\"].split(\"_\")[0].split(\" \")[0]] + [row[\"feature\"].split(\"_\")[1]]))\n",
    "        if len(row[\"feature\"].split(\"_\")[0].split(\" \")) > 2:\n",
    "            feature_variations.append((\" \").join(row[\"feature\"].split(\"_\")[0].split(\" \")[:2] + [row[\"feature\"].split(\"_\")[1]]))\n",
    "        if len(row[\"feature\"].split(\"_\")[1].split(\" \")) > 1:\n",
    "            feature_variations.append((\" \").join([row[\"feature\"].split(\"_\")[0]] + row[\"feature\"].split(\"_\")[1].split(\" \")[1:]))\n",
    "\n",
    "    if not most_common_feature in feature_variations:\n",
    "        print(\"--------\")\n",
    "        print(\"Warning\")\n",
    "        print(f\"For concept '{row.concept}'\")\n",
    "        print(f\"The most common feature ({most_common_feature}) should be among the potential features listed with '_' ({feature_variations})\")\n",
    "        most_common_feature = feature_variations[0]\n",
    "        print(f\"Picking first option ({most_common_feature})\")\n",
    "    return most_common_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_data[\"participant list\"] = visual_data[\"participant list\"].apply(get_participant_counts_from_participant_list)\n",
    "visual_data[\"feature\"] = visual_data.apply(pick_most_common_feature, axis=1)\n",
    "visual_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature relations\n",
    "(The starting phrase before the actual feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_data[\"feature_starter\"] = visual_data.feature.apply(lambda x: (' ').join(x.split(' ')[:-1]))\n",
    "visual_data[\"feature_main\"] = visual_data.feature.apply(lambda x: x.split(' ')[-1].split('_')[0])\n",
    "visual_data = visual_data.drop(columns=[\"feature\"])\n",
    "visual_data = visual_data.drop(columns=[\"feature alternatives\"])\n",
    "visual_data = visual_data.drop(columns=[\"participant list\"])\n",
    "visual_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the frequency of 'is a' is very low compared to the 506 frequency in tacit assumptions! Probably due to that we only look at visual concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only include the most common feature starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_STARTERS_TO_INCLUDE = {\"is\", \"has\", \"has a\", \"made of\"}\n",
    "starter_mask = [feature_starter in FEATURE_STARTERS_TO_INCLUDE for feature_starter in visual_data.feature_starter]\n",
    "visual_data = visual_data[starter_mask]\n",
    "made_of_mask = visual_data.feature_starter==\"made of\"\n",
    "visual_data.loc[made_of_mask, \"feature_starter\"] = \"is made of\"\n",
    "visual_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only include feature alternatives that are described by one wordpiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_base_vocab = tokenizer.get_vocab()\n",
    "vocab_mask = [feature in bert_base_vocab for feature in visual_data.feature_main]\n",
    "\n",
    "visual_data = visual_data[vocab_mask]\n",
    "visual_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_data.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create partitions based on minimum production frequencies\n",
    "The data will be partitioned to include all features with at least the specified pf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_SPLITS = [2, 5, 10, 20, 30]\n",
    "visual_data[visual_data.pf>=PF_SPLITS[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in PF_SPLITS:\n",
    "    file_path = \"data/pf-partitions/\"+str(split)+\".csv\"\n",
    "    visual_data[visual_data.pf>=split].to_csv(file_path, columns=[\"concept\",\"feature_starter\",\"feature_main\"], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the evaluation queries\n",
    "* Fix article before item (\"a\", \"an\" or nothing if uncountable noun)\n",
    "  * _Done through manual annotation!_\n",
    "* Handle different query templates\n",
    "  * _Done! Currently have four different query templates. Worth investigating if they always work out._\n",
    "* (Look for visual sequence perceptual features, that can only be seen from videos?)\n",
    "\n",
    "Example:\n",
    "\n",
    "{\"query\": \"Q: an alligator is? A: [MASK]\", \"labels\": [\"green\", \"big\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = pd.read_csv(\"data/descriptors.csv\", keep_default_na=False)\n",
    "descriptors = {row.concept: row.descriptor for _, row in descriptors.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "QUERY_TEMPLATES = [\"[DESCRIPTOR] [CONCEPT] [FEATURE_STARTER] [MASK].\",\n",
    "                   \"everybody knows that [DESCRIPTOR] [CONCEPT] [FEATURE_STARTER] [MASK].\",\n",
    "                   \"[DESCRIPTOR] [CONCEPT] usually [FEATURE_STARTER] [MASK].\",\n",
    "                   \"q: [DESCRIPTOR] [CONCEPT] [FEATURE_STARTER]? a: [MASK].\",\n",
    "                   \"q: [DESCRIPTOR] [CONCEPT] usually [FEATURE_STARTER]? a: [MASK].\",\n",
    "                   \"generally, [DESCRIPTOR] [CONCEPT] [FEATURE_STARTER] [MASK].\",\n",
    "                   \"[DESCRIPTOR] [CONCEPT] generally [FEATURE_STARTER] [MASK].\",\n",
    "                   \"describe the properties of [DESCRIPTOR] [CONCEPT]. [DESCRIPTOR] [CONCEPT] [FEATURE_STARTER] [MASK].\",\n",
    "                   \"describe the properties of [DESCRIPTOR] [CONCEPT]. [DESCRIPTOR] [CONCEPT] usually [FEATURE_STARTER] [MASK].\"]\n",
    "\n",
    "for query_ix, query_template in enumerate(QUERY_TEMPLATES):\n",
    "    for split in PF_SPLITS:\n",
    "        filename = \"data/queries/template_\" + str(query_ix) + \"_pf_\" + str(split) + \".jsonl\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            visual_data = pd.read_csv(\"data/pf-partitions/\" + str(split) + \".csv\")\n",
    "            for concept, feature_starter in list(visual_data.groupby([\"concept\",\"feature_starter\"]).count().index):\n",
    "                query = query_template.replace(\"[DESCRIPTOR]\", descriptors[concept]).replace(\"[CONCEPT]\", concept.replace('_', ' ')).replace(\"[FEATURE_STARTER]\", feature_starter).replace(\"  \", \" \")\n",
    "\n",
    "                json_entry = {\"query\": query.strip(), \n",
    "                              \"labels\": list(visual_data[(visual_data.concept==concept) & (visual_data.feature_starter==feature_starter)].feature_main.values),\n",
    "                              \"concept\": concept,\n",
    "                              \"query_template\": query_template,\n",
    "                              \"feature_starter\": feature_starter,\n",
    "                              \"pf\": split}\n",
    "                json.dump(json_entry, f)\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of tokens to mask task answers for\n",
    "There are a total of 614 possible answer alternatives to this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_data = pd.read_csv(\"data/pf-partitions/2.csv\")\n",
    "np.savetxt(\"data/labels.txt\", np.sort(visual_data.feature_main.unique()), delimiter=\"\\n\", fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dl4nlp_assignment_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "05753275db4c417a6068616f81db8df1fa4ccdafd9acd0a9b6ad9f4706cb5748"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
